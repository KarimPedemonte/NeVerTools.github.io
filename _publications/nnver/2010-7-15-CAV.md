---
title: "An Abstraction-Refinement Approach to Verification of Artificial Neural Networks"
collection: publications
permalink: /publication/2010-7-15-CAV
excerpt: 'This paper is the first proposal of an automated verification approach for (shallow) neural networks.'
date: 2010-7-15
venue: 'Computer Aided Verification, 22nd International Conference, CAV 2010'
paperurl: 'http://nevertools.github.io/files/2010_CAV.pdf'
citation: 'Luca Pulina, Armando Tacchella -
<b>An Abstraction-Refinement Approach to Verification of Artificial Neural Networks</b>. CAV 2010: 243-257'
---

A key problem in the adoption of artificial neural networks in safetyrelated applications is that misbehaviors can be hardly ruled out with traditional
analytical or probabilistic techniques. In this paper we focus on specific networks
known as Multi-Layer Perceptrons (MLPs), and we propose a solution to verify their safety using abstractions to Boolean combinations of linear arithmetic
constraints. We show that our abstractions are consistent, i.e., whenever the abstract MLP is declared to be safe, the same holds for the concrete one. Spurious
counterexamples, on the other hand, trigger refinements and can be leveraged
to automate the correction of misbehaviors. We describe an implementation of
our approach based on the HYSAT solver, detailing the abstraction-refinement
process and the automated correction strategy. Finally, we present experimental
results confirming the feasibility of our approach on a realistic case study.


